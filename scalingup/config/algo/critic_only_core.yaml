defaults:
  - critic_backbone@critic_backbone1: medium
  - critic_backbone@critic_backbone2: medium
  - state_sequence_encoder@state_sequence_encoder1: default
  - state_sequence_encoder@state_sequence_encoder2: default
  - optimizer: adamw
  - lr_scheduler: cosine
  - ../ctrl_config@ctrl_config: four_hertz
  - rollout_config: default
  - _self_

_target_: scalingup.algo.critics_algo_multiGPU.CriticTrainingAlgo
_recursive_: true
_convert_: dict
action_dim: ???
float32_matmul_precision: medium

# obs encoder
state_sequence_encoder1:
  rollout_config: ${..rollout_config}
  should_condition_on_vision: true
  vision_encoder:
    vision_obs_horizon: ${...rollout_config.vision_obs_horizon}
state_sequence_encoder2:
  rollout_config: ${..rollout_config}
  should_condition_on_vision: true
  vision_encoder:
    vision_obs_horizon: ${...rollout_config.vision_obs_horizon}

replay_buffer:
  proprioception_keys: ${..state_sequence_encoder1.proprioception_keys}
  obs_cameras: ${obs_cameras}
  # if not conditioning on success, then should just filter out imperfect trajectories
  filter_negatives: ${eval:"not ${..should_condition_on_task_metric}"}
  # eventually don't learn from ground truth task success, only from inferred
  filter_manually_designed_trajectories: false
  rollout_config: ${..rollout_config}

critic_backbone1:
  input_dim: ${..action_dim}
  global_cond_dim: ${eval:"${..state_sequence_encoder1.task_desc_proj.out_features}*int(${..state_sequence_encoder1.should_condition_on_text}) + ${..state_sequence_encoder1.proprio_dim} * ${..rollout_config.proprio_obs_horizon} + ${..state_sequence_encoder1.vision_encoder.output_dim} * ${..rollout_config.vision_obs_horizon}*int(${..state_sequence_encoder1.should_condition_on_vision})"}
critic_backbone2:
  input_dim: ${..action_dim}
  global_cond_dim: ${eval:"${..state_sequence_encoder1.task_desc_proj.out_features}*int(${..state_sequence_encoder1.should_condition_on_text}) + ${..state_sequence_encoder1.proprio_dim} * ${..rollout_config.proprio_obs_horizon} + ${..state_sequence_encoder1.vision_encoder.output_dim} * ${..rollout_config.vision_obs_horizon}*int(${..state_sequence_encoder1.should_condition_on_vision})"}

# debugging stats config
num_validation_batches: 32

# critic training
max_q_backup: true
actor_checkpoint_path: ???
monte_carlo: true
actor_inference_device: cuda
log_grad_frequence: 50
gamma: 0.98
tau: 0.005

